# -*- coding: utf-8 -*-
"""
Created on Sun Oct  5 13:22:38 2025

@author: villa
"""
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from scipy.stats import zscore
from fpdf import FPDF
from dotenv import load_dotenv
import os, json, gc
from datetime import datetime

# ===================== CONFIGURA√á√ÉO INICIAL =====================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
st.set_page_config(page_title="Agente EDA Gen√©rico", layout="wide")
st.title("ü§ñ Agente de An√°lise de CSV ‚Äî EDA Gen√©rico (Vers√£o Otimizada)")

HISTORY_PATH = "agent_history.json"

# ===================== FUN√á√ïES AUXILIARES =====================
def load_history():
    if os.path.exists(HISTORY_PATH):
        try:
            with open(HISTORY_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_history(hist):
    hist = hist[-20:]  # manter apenas √∫ltimas 20 entradas
    with open(HISTORY_PATH, "w", encoding="utf-8") as f:
        json.dump(hist, f, ensure_ascii=False, indent=2)
    return hist

def clear_history():
    """Limpa o hist√≥rico de perguntas e respostas."""
    st.session_state.history = []
    try:
        with open(HISTORY_PATH, "w", encoding="utf-8") as f:
            json.dump([], f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"Erro ao limpar o hist√≥rico: {e}")
        return False

if "history" not in st.session_state:
    st.session_state.history = load_history()

@st.cache_data(show_spinner=False)
def load_csv(file):
    df = pd.read_csv(file)
    for col in df.columns:
        if df[col].dtype == 'object':
            try:
                df[col] = pd.to_numeric(df[col])
            except Exception:
                pass
    return df

# ===================== NOVA FUN√á√ÉO: CONCLUS√ïES AUTOM√ÅTICAS =====================
def gerar_conclusoes(df):
    num_cols = df.select_dtypes(include=['float64','int64']).columns.tolist()
    conclusions = []

    # 1. Valores extremos
    z_scores = np.abs(zscore(df[num_cols]))
    outliers_count = (z_scores > 3).sum(axis=0)
    outlier_cols = [col for col, count in zip(num_cols, outliers_count) if count > 0]
    if outlier_cols:
        conclusions.append(f"As colunas {outlier_cols} possuem outliers significativos que podem afetar a an√°lise.")
    else:
        conclusions.append("N√£o foram detectados outliers relevantes.")

    # 2. Tend√™ncia central
    high_mean_cols = df[num_cols].mean().sort_values(ascending=False).head(3).index.tolist()
    conclusions.append(f"As colunas com maiores m√©dias s√£o: {high_mean_cols}")

    # 3. Correla√ß√£o
    corr = df[num_cols].corr().abs()
    high_corr_pairs = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))
    high_corr_pairs = high_corr_pairs.stack().sort_values(ascending=False)
    if not high_corr_pairs.empty:
        top_corr = high_corr_pairs.head(3)
        conclusions.append(f"Maiores correla√ß√µes entre vari√°veis: {top_corr.to_dict()}")
    else:
        conclusions.append("N√£o h√° correla√ß√µes fortes entre as vari√°veis.")

    # 4. Valores extremos de transa√ß√µes (para dataset de fraude)
    if 'Amount' in df.columns:
        high_amounts = df['Amount'].sort_values(ascending=False).head(5).tolist()
        conclusions.append(f"Maiores valores de transa√ß√£o detectados: {high_amounts}")

    return "\n".join(conclusions)

# ===================== GERA√á√ÉO DE PDF COMPLETA =====================
# ===================== GERA√á√ÉO DE PDF COMPLETA =====================
def gerar_pdf(hist, conclusoes=None, framework="Streamlit + Python", estrutura="EDA Gen√©rico"):
    """
    Gera PDF completo com:
    - Framework escolhida
    - Estrutura da solu√ß√£o
    - Perguntas/respostas (m√≠nimo 4, com pelo menos 1 gr√°fico)
    - Pergunta sobre conclus√µes do agente
    - C√≥digo-fonte ou arquivo JSON exportado
    - Link para acessar o agente
    """
    pdf = FPDF()
    pdf.add_page()
    
    # Adiciona fonte Unicode
    pdf.add_font("DejaVu", "", "DejaVuSans.ttf", uni=True)
    pdf.set_auto_page_break(auto=True, margin=15)

    # Fun√ß√µes de formata√ß√£o
    def write_text(text, bold=False, size=11):
        style = "B" if bold else ""
        pdf.set_font("DejaVu", style, size)
        pdf.multi_cell(0, 7, str(text))

    def format_list(l):
        return ", ".join([str(i) for i in l])

    def format_dict(d):
        return "\n".join([f"{k}: {v}" for k, v in d.items()])

    # Cabe√ßalho
    pdf.set_font("DejaVu", "B", 16)
    pdf.cell(0, 10, "Agentes Aut√¥nomos ‚Äì Relat√≥rio da Atividade Extra", ln=True, align="C")
    pdf.ln(5)
    pdf.set_font("DejaVu", "", 12)
    pdf.cell(0, 10, f"Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", ln=True, align="C")
    pdf.ln(10)

    # 1. Framework escolhida
    pdf.set_font("DejaVu", "B", 14)
    pdf.cell(0, 10, "1. Framework Escolhida", ln=True)
    pdf.ln(3)
    write_text(framework)
    pdf.ln(5)

    # 2. Estrutura da solu√ß√£o
    pdf.set_font("DejaVu", "B", 14)
    pdf.cell(0, 10, "2. Estrutura da Solu√ß√£o", ln=True)
    pdf.ln(3)
    write_text(estrutura)
    pdf.ln(5)

    # 3. Perguntas e respostas (m√≠nimo 4)
    pdf.set_font("DejaVu", "B", 14)
    pdf.cell(0, 10, "3. Perguntas e Respostas", ln=True)
    pdf.ln(5)

    min_perguntas = 4
    perguntas = hist[-min_perguntas:] if len(hist) >= min_perguntas else hist
    for i, h in enumerate(perguntas, 1):
        query = h['query']
        result = h['result']
        try:
            parsed = eval(result)
            if isinstance(parsed, dict):
                result = format_dict(parsed)
            elif isinstance(parsed, list):
                result = format_list(parsed)
        except:
            pass
        if "gr√°fico" in result.lower():
            result += " (Resultado apresentado em gr√°fico)"
        write_text(f"{i}. Pergunta: {query}", bold=True, size=12)
        write_text(f"Resposta: {result}", size=11)
        pdf.ln(3)

    # 4. Conclus√µes do agente
    if conclusoes:
        pdf.set_font("DejaVu", "B", 14)
        pdf.cell(0, 10, "4. Conclus√µes do Agente", ln=True)
        pdf.ln(3)
        write_text(conclusoes, size=11)
        pdf.ln(5)

    # 5. C√≥digo-fonte / JSON exporta√ß√£o
    pdf.set_font("DejaVu", "B", 14)
    pdf.cell(0, 10, "5. C√≥digo Fonte / Exporta√ß√£o JSON", ln=True)
    pdf.ln(3)
    write_text("O c√≥digo-fonte est√° dispon√≠vel no arquivo principal ou via exporta√ß√£o JSON do N8N.", size=11)
    pdf.ln(5)

    # 6. Link de acesso ao agente
    pdf.set_font("DejaVu", "B", 14)
    pdf.cell(0, 10, "6. Link de Acesso ao Agente", ln=True)
    pdf.ln(3)
    write_text("Acesse seu agente aqui: https://seu-agente-exemplo.com", size=11)
    pdf.ln(5)

    # Retorna bytes do PDF pronto
    pdf_bytes = pdf.output(dest='S').encode('utf-8')
    return pdf_bytes


# ===================== INTERFACE PRINCIPAL =====================
st.sidebar.header("üìò Instru√ß√µes")
st.sidebar.markdown("""
1. Carregue um CSV  
2. Fa√ßa perguntas sobre o dataset  
3. O agente responde com an√°lise objetiva  
4. Gere conclus√µes e exporte o PDF  
5. Use o bot√£o abaixo para limpar o hist√≥rico de perguntas
""")

uploaded_file = st.file_uploader("üìÇ Carregue o CSV", type="csv")

if uploaded_file:
    df = load_csv(uploaded_file)
    st.success(f"CSV carregado! Formato: {df.shape}")

    MAX_SAMPLE = 50000
    df_sample = df.sample(MAX_SAMPLE, random_state=42) if len(df) > MAX_SAMPLE else df

    numerical_columns = df_sample.select_dtypes(include=['float64','int64']).columns.tolist()
    categorical_columns = df_sample.select_dtypes(include=['object']).columns.tolist()

    # Bot√£o para limpar o hist√≥rico
    if st.button("üóëÔ∏è Limpar Hist√≥rico de Perguntas"):
        if clear_history():
            st.success("Hist√≥rico de perguntas limpo com sucesso!")
        else:
            st.error("Falha ao limpar o hist√≥rico. Verifique as permiss√µes do arquivo.")

    query = st.text_input("Fa√ßa sua pergunta de EDA:")

    if query:
        st.info("ü§ñ Gerando an√°lise objetiva...")
        query_lower = query.lower()
        result = ""

        # ==== DESCRI√á√ÉO, PADR√ïES, OUTLIERS, RELA√á√ïES ====
        if "tipo" in query_lower or "categoria" in query_lower:
            result = f"Colunas num√©ricas: {numerical_columns}\nColunas categ√≥ricas: {categorical_columns}"

        elif "distribui√ß√£o" in query_lower:
            n_cols_per_row = 3
            num_cols = len(numerical_columns)
            for i in range(0, num_cols, n_cols_per_row):
                cols = st.columns(n_cols_per_row)
                for j, col in enumerate(numerical_columns[i:i+n_cols_per_row]):
                    with cols[j]:
                        fig, ax = plt.subplots(figsize=(4,3))
                        sns.histplot(df_sample[col].dropna(), bins=10, kde=True, ax=ax)
                        ax.set_title(col, fontsize=10)
                        ax.set_xlabel("")
                        ax.set_ylabel("")
                        st.pyplot(fig)
                        plt.close(fig)
                        gc.collect()
            for col in categorical_columns:
                result += f"\nColuna {col} - Contagem por categoria:\n{df_sample[col].value_counts().to_dict()}"

        elif "intervalo" in query_lower or "m√≠nimo" in query_lower or "m√°ximo" in query_lower:
            result = df_sample[numerical_columns].agg(['min','max']).to_string()

        elif "tend√™ncia central" in query_lower or "m√©dia" in query_lower or "mediana" in query_lower:
            result = df_sample[numerical_columns].agg(['mean','median']).to_string()

        elif "variabilidade" in query_lower or "desvio padr√£o" in query_lower or "vari√¢ncia" in query_lower:
            result = df_sample[numerical_columns].agg(['std','var']).to_string()

        elif "padr√µes" in query_lower or "tend√™ncias temporais" in query_lower:
            if 'Time' in df_sample.columns and 'Amount' in df_sample.columns:
                fig, ax = plt.subplots(figsize=(10,5))
                ax.plot(df_sample['Time'], df_sample['Amount'])
                ax.set_title('Tend√™ncia temporal de Amount')
                ax.set_xlabel('Time')
                ax.set_ylabel('Amount')
                st.pyplot(fig)
                plt.close(fig)
                gc.collect()
                result = "Gr√°fico de tend√™ncia temporal gerado."
            else:
                result = "Coluna 'Time' ou 'Amount' n√£o encontrada."

        elif "valores mais frequentes" in query_lower or "menos frequentes" in query_lower:
            for col in df_sample.columns:
                vc = df_sample[col].value_counts()
                result += f"\nColuna: {col}\nMais frequentes: {vc.head(5).to_dict()}\nMenos frequentes: {vc.tail(5).to_dict()}"

        elif "clusters" in query_lower or "agrupamentos" in query_lower:
            if len(df_sample) > 20000:
                st.warning(f"O dataset tem {len(df_sample):,} linhas. Usando amostra de 10.000 para clusteriza√ß√£o.")
                df_cluster = df_sample.sample(10000, random_state=42)
            else:
                df_cluster = df_sample.copy()
                
            try:     
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(df_sample[numerical_columns])
                pca = PCA(n_components=2)
                X_pca = pca.fit_transform(X_scaled)
                kmeans = KMeans(n_clusters=3, random_state=42).fit(X_scaled)
                
                fig, ax = plt.subplots(figsize=(8,6))
                scatter = ax.scatter(X_pca[:,0], X_pca[:,1], c=kmeans.labels_, cmap='viridis', alpha=0.6)
                ax.set_title("Clusters (amostra reduzida via PCA + KMeans)")
                st.pyplot(fig)
                plt.close(fig)
                gc.collect()
                result = f"Clusters gerados com amostra de {len(df_cluster):,} linhas."
                
            except Exception as e:
               result = f"Erro ao gerar clusters: {e}"

        elif "valores at√≠picos" in query_lower or "outliers" in query_lower:
            z_scores = np.abs(zscore(df_sample[numerical_columns]))
            outliers_count = (z_scores > 3).sum(axis=0)
            result = f"Outliers por coluna:\n{dict(zip(numerical_columns, outliers_count))}"

        elif "afetam a an√°lise" in query_lower:
            z_scores = np.abs(zscore(df_sample[numerical_columns]))
            df_no_outliers = df_sample[(z_scores < 3).all(axis=1)]
            result = f"Antes:\n{df_sample[numerical_columns].describe().T}\n\nDepois (sem outliers):\n{df_no_outliers[numerical_columns].describe().T}"

        elif "removidos" in query_lower or "transformados" in query_lower or "investigados" in query_lower:
            result = "Recomenda-se: remover outliers extremos, transformar vari√°veis ou investigar casos espec√≠ficos."

        elif "relacionadas" in query_lower or "dispers√£o" in query_lower:
            subset_cols = numerical_columns[:5]
            pairgrid = sns.pairplot(df_sample[subset_cols])
            st.pyplot(pairgrid.fig)
            plt.close(pairgrid.fig)
            gc.collect()
            result = "Pairplot gerado (apenas primeiras 5 colunas num√©ricas)."

        elif "correla√ß√£o" in query_lower:
            corr = df_sample[numerical_columns].corr()
            fig, ax = plt.subplots(figsize=(12,8))
            sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", ax=ax)
            st.pyplot(fig)
            plt.close(fig)
            gc.collect()
            high_corr = corr.unstack().sort_values(ascending=False)
            high_corr = high_corr[high_corr < 1]
            top_corr = high_corr[0:5]
            result = f"Heatmap de correla√ß√£o gerado.\nSim, h√° correla√ß√£o significativa entre algumas vari√°veis, por exemplo:\n{top_corr.to_string()}"

        elif "influ√™ncia" in query_lower:
            corr_sum = df_sample[numerical_columns].corr().abs().sum().sort_values(ascending=False)
            top_5 = corr_sum.head(5)
            low_5 = corr_sum.tail(5)
            result = f"Vari√°veis com maior influ√™ncia:\n{top_5.to_string()}\n\nVari√°veis com menor influ√™ncia:\n{low_5.to_string()}"

        else:
            result = "Pergunta n√£o reconhecida ou n√£o implementada para an√°lise objetiva."

        st.subheader("Resultado da An√°lise")
        st.text(result)
        st.session_state.history.append({"query": query, "result": result})
        st.session_state.history = save_history(st.session_state.history)

    st.markdown("---")

    # ==== Bot√£o de gerar PDF com conclus√µes ====
    if st.button("üìÑ Gerar Relat√≥rio PDF"):
        conclusoes_text = gerar_conclusoes(df_sample)
        pdf_bytes = gerar_pdf(st.session_state.history, conclusoes_text)
        st.download_button(
            "Baixar Relat√≥rio PDF",
            data=pdf_bytes,
            file_name="Agentes_Autonomos_Relatorio.pdf",
            mime="application/pdf"
        )

    st.markdown("### Visualizar parte do dataset")
    st.dataframe(df_sample.head(200))

else:
    st.info("üí° Carregue um CSV para come√ßar.")